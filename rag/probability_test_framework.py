import json
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from typing import List, Dict, Tuple, Optional
import pandas as pd
from tqdm import tqdm
import time
from datetime import datetime
import os
import re
import pickle
from pathlib import Path

class ProbabilityTestFramework:
    def __init__(self, 
                 model_name: str, 
                 device: str = "cuda",
                 use_quantization: bool = False,
                 quantization_bits: int = 4,
                 local_model_path: str = None,
                 temperature: float = 0.0,
                 
                 use_rag: bool = False,
                 rag_system = None,
                 rag_k: int = 3):
        """
        åˆå§‹åŒ–æµ‹è¯•æ¡†æ¶
        
        Args:
            model_name: æ¨¡å‹åç§°
            device: è¿è¡Œè®¾å¤‡
            use_quantization: æ˜¯å¦ä½¿ç”¨é‡åŒ–
            quantization_bits: é‡åŒ–ä½æ•° (4 or 8)
            local_model_path: æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
            temperature: ç”Ÿæˆæ¸©åº¦ï¼ˆ0ä¸ºç¡®å®šæ€§è¾“å‡ºï¼‰
            use_rag: æ˜¯å¦ä½¿ç”¨RAGå¢å¼º
            rag_system: RAGç³»ç»Ÿå®ä¾‹ï¼ˆProbabilityRAGå¯¹è±¡ï¼‰
            rag_k: æ£€ç´¢çš„ç›¸å…³é—®é¢˜æ•°é‡
        """
        self.temperature = temperature
        self.use_rag = use_rag
        self.rag_system = rag_system
        self.rag_k = rag_k

        if use_rag and rag_system is None:
            raise ValueError("rag_system instance needed")
            
        # å†³å®šå®é™…åŠ è½½è·¯å¾„
        actual_model_path = model_name
        if local_model_path and os.path.exists(local_model_path):
            actual_model_path = local_model_path
            print(f"âœ“ ä»æœ¬åœ°åŠ è½½æ¨¡å‹: {local_model_path}")
        else:
            if local_model_path:
                print(f"âš ï¸ æœ¬åœ°è·¯å¾„ä¸å­˜åœ¨: {local_model_path}")
            print(f"ä» HuggingFace åŠ è½½æ¨¡å‹: {model_name}")
        
        print(f"  é‡åŒ–: {'æ˜¯ (' + str(quantization_bits) + '-bit)' if use_quantization else 'å¦ (BF16)'}")
        print(f"  æ¸©åº¦: {temperature} ({'ç¡®å®šæ€§' if temperature == 0 else 'éšæœºæ€§'})")
        
        self.model_name = model_name
        self.device = device
        self.use_quantization = use_quantization
        
        # åŠ è½½åˆ†è¯å™¨
        self.tokenizer = AutoTokenizer.from_pretrained(
            actual_model_path,
            use_fast=False,
            trust_remote_code=True
        )
        
        # é…ç½®é‡åŒ–å‚æ•°
        if use_quantization:
            from transformers import BitsAndBytesConfig
            
            if quantization_bits == 4:
                quant_config = BitsAndBytesConfig(
                    load_in_4bit=True,
                    bnb_4bit_use_double_quant=True,
                    bnb_4bit_quant_type="nf4",
                    bnb_4bit_compute_dtype=torch.bfloat16,
                )
            elif quantization_bits == 8:
                quant_config = BitsAndBytesConfig(
                    load_in_8bit=True,
                )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„é‡åŒ–ä½æ•°: {quantization_bits}")
            
            # åŠ è½½é‡åŒ–æ¨¡å‹
            self.model = AutoModelForCausalLM.from_pretrained(
                actual_model_path,
                device_map="auto",
                torch_dtype=torch.bfloat16,
                quantization_config=quant_config,
                trust_remote_code=True,
            )
        else:
            # åŠ è½½ BF16 æ¨¡å‹
            self.model = AutoModelForCausalLM.from_pretrained(
                actual_model_path,
                device_map="auto",
                torch_dtype=torch.bfloat16,
                trust_remote_code=True
            )
        
        # åˆ¤æ–­æ¨¡å‹ç±»å‹
        self.is_thinking = "thinking" in model_name.lower()
        
        print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ! ç±»å‹: {'Thinking' if self.is_thinking else 'Instruct'}")

    def format_question(self, item: Dict, language: str = "english") -> str:
        """
        æ ¼å¼åŒ–é—®é¢˜ä¸º prompt
        è‡ªåŠ¨é€‰æ‹©åŸºç¡€ç‰ˆæœ¬æˆ–RAGå¢å¼ºç‰ˆæœ¬
        """
        if self.use_rag:
            return self._format_question_with_rag(item, language)
        else:
            return self._format_question_basic(item, language)
    
    def _format_question_basic(self, item: Dict, language: str = "english") -> str:
          """
        ä¿®å¤ç‰ˆæœ¬ï¼šæ·»åŠ æ•°å­¦ç­‰ä»·æ€§æç¤º
        """
        lang_data = item[language]
        
        # ä½¿ç”¨æ•°å­—æ ‡è®°é€‰é¡¹ï¼ˆ1, 2, 3, ...ï¼‰
        options_text = ""
        for i, option in enumerate(lang_data['options'], 1):
            options_text += f"{i}. {option}\n"
        
        # æ ¹æ®è¯­è¨€è°ƒæ•´ prompt
        if language == "english":
            prompt = f"""Please solve the following probability theory problem and select the correct answer.
    
    Context: {lang_data['context']}
    
    Question: {lang_data['question']}
    
    Options:
    {options_text}
    
    IMPORTANT NOTES:
    - Mathematical expressions may be written in different equivalent forms
    - For example: sqrt(a^2 * b) equals a * sqrt(b)
    - Expression order doesn't matter: e^(-A) * Î£(...) equals Î£(...) * e^(-A)
    - Consider algebraic equivalence when comparing your answer to the options
    - If your derived expression matches an option algebraically, select that option
    
    Please respond with your reasoning followed by a JSON object in this exact format:
    {{"answer": N}}
    
    where N is the number of your chosen option (1, 2, 3, 4, 5, or 6).
    Option 6 ("Ved ikke" / "Do not know") should ONLY be selected if:
    - The problem is genuinely unsolvable with given information, OR
    - All options are clearly incorrect, OR  
    - You cannot derive any reasonable answer
    
    Your response:"""
        else:  # danish
            prompt = f"""LÃ¸s fÃ¸lgende sandsynlighedsteori problem og vÃ¦lg det rigtige svar.
    
    Kontekst: {lang_data['context']}
    
    SpÃ¸rgsmÃ¥l: {lang_data['question']}
    
    Valgmuligheder:
    {options_text}
    
    VIGTIGE NOTER:
    - Matematiske udtryk kan vÃ¦re skrevet i forskellige Ã¦kvivalente former
    - For eksempel: sqrt(a^2 * b) er lig med a * sqrt(b)
    - UdtrykrÃ¦kkefÃ¸lge betyder ikke noget: e^(-A) * Î£(...) er lig med Î£(...) * e^(-A)
    - Overvej algebraisk Ã¦kvivalens nÃ¥r du sammenligner dit svar med valgmulighederne
    - Hvis dit udledte udtryk matcher en valgmulighed algebraisk, vÃ¦lg den valgmulighed
    
    Svar venligst med din rÃ¦sonnering efterfulgt af et JSON-objekt i dette nÃ¸jagtige format:
    {{"answer": N}}
    
    hvor N er nummeret pÃ¥ dit valgte svarmulighed (1, 2, 3, 4, 5 eller 6).
    Valgmulighed 6 ("Ved ikke") skal KUN vÃ¦lges hvis:
    - Problemet er Ã¦gte ulÃ¸seligt med given information, ELLER
    - Alle valgmuligheder er klart forkerte, ELLER
    - Du kan ikke udlede noget rimeligt svar
    
    Dit svar:"""
        
        return prompt


    def _format_question_with_rag(self, item: Dict, language: str = "english") -> str:
        lang_data = item[language]
        
        # 1. æ„é€ æŸ¥è¯¢æ–‡æœ¬
        query = f"{lang_data['context']} {lang_data['question']}".strip()
        
        # 2. ä½¿ç”¨RAGæ£€ç´¢ç›¸å…³é—®é¢˜
        try:
            retrieved_questions = self.rag_system.retrieve_relevant(
                query, 
                k=self.rag_k,
                use_diversity=True,
                use_weights=True
            )
        except Exception as e:
            print(f"RAGæ£€ç´¢å¤±è´¥: {e}, é™çº§ä¸ºåŸºç¡€prompt")
            return self._format_question_basic(item, language)
        
        # 3. æ„å»ºå¢å¼ºprompt
        prompt_parts = []
        
        # æ·»åŠ ç³»ç»ŸæŒ‡ä»¤
        if language == "english":
            prompt_parts.append(
                "You are an expert in probability and statistics. "
                "Use the following similar problems as reference to solve the given problem.\n\n"
            )
        else:  # danish
            prompt_parts.append(
                "Du er ekspert i sandsynlighedsteori og statistik. "
                "Brug fÃ¸lgende lignende problemer som reference til at lÃ¸se det givne problem.\n\n"
            )
        
        # æ·»åŠ å‚è€ƒé—®é¢˜
        if retrieved_questions:
            prompt_parts.append("=== REFERENCE PROBLEMS ===\n\n")
            
            for i, q in enumerate(retrieved_questions, 1):
                prompt_parts.append(f"Reference {i}:\n")
                
                # Context
                if q.context:
                    prompt_parts.append(f"Context: {q.context}\n")
                
                # Question
                prompt_parts.append(f"Question: {q.question}\n")
                
                # Correct answer (1-indexed)
                prompt_parts.append(f"Correct Answer: Option {q.answer_index + 1}\n")
                
                # å…³é”®æ­¥éª¤ï¼ˆç²¾ç®€ç‰ˆï¼‰
                if q.explanation_key_steps and len(q.explanation_key_steps) > 0:
                    prompt_parts.append("Key steps:\n")
                    for step in q.explanation_key_steps[:3]:  # åªå–å‰3æ­¥
                        prompt_parts.append(f"  - {step}\n")
                
                # å…³é”®å…¬å¼ï¼ˆç²¾ç®€ç‰ˆï¼‰
                if q.explanation_formulae and len(q.explanation_formulae) > 0:
                    prompt_parts.append("Key formulae:\n")
                    for formula in q.explanation_formulae[:2]:  # åªå–å‰2ä¸ª
                        prompt_parts.append(f"  - {formula}\n")
                
                prompt_parts.append("\n")
        
        # æ·»åŠ åˆ†éš”ç¬¦
        prompt_parts.append("=== PROBLEM TO SOLVE ===\n\n")
        
        # æ·»åŠ å½“å‰é—®é¢˜çš„context
        if lang_data['context']:
            prompt_parts.append(f"Context: {lang_data['context']}\n")
        
        # æ·»åŠ é—®é¢˜
        prompt_parts.append(f"Question: {lang_data['question']}\n\n")
        
        # æ·»åŠ é€‰é¡¹
        prompt_parts.append("Options:\n")
        for i, opt in enumerate(lang_data['options'], 1):
            prompt_parts.append(f"{i}. {opt}\n")
        
        # æ·»åŠ è¾“å‡ºæ ¼å¼è¦æ±‚
        if language == "english":
            prompt_parts.append(
                "\nPlease respond with your reasoning followed by a JSON object in this exact format:\n"
                '{"answer": N}\n\n'
                "where N is the number of your chosen option (1, 2, 3, 4, 5, or 6).\n\n"
                "Your response:"
            )
        else:
            prompt_parts.append(
                "\nSvar venligst med din rÃ¦sonnering efterfulgt af et JSON-objekt i dette nÃ¸jagtige format:\n"
                '{"answer": N}\n\n'
                "hvor N er nummeret pÃ¥ dit valgte svarmulighed (1, 2, 3, 4, 5 eller 6).\n\n"
                "Dit svar:"
            )
        
        return ''.join(prompt_parts)        
    
    def generate_answer(self, prompt: str, max_tokens: int = 2000) -> Dict:
        """
        ç”Ÿæˆç­”æ¡ˆï¼ˆæ¨èå®ç°ï¼šå…ˆå®Œæ•´/çŸ­ç‰‡æ®µç”Ÿæˆï¼Œå†æ£€æµ‹é‡å¤å¹¶å†³å®šæ˜¯å¦è·³è¿‡ï¼‰ã€‚
        è¯´æ˜ï¼šæ­¤å®ç°é¿å…è¯•å›¾å¼ºåˆ¶ä¸­æ–­ model.generateï¼Œä»è€Œä¸ä¼šç•™ä¸‹å ç”¨ GPU çš„åå°çº¿ç¨‹ã€‚
        """
        print(f"\nprompté•¿åº¦: {len(prompt)} å­—ç¬¦")
        messages = [{"role": "user", "content": prompt}]
        
        text = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True,
            enable_thinking=self.is_thinking
        )
        
        inputs = self.tokenizer([text], return_tensors="pt").to(self.model.device)
        # ç”Ÿæˆé…ç½®ï¼ˆå¯æŒ‰éœ€å¾®è°ƒï¼‰
        gen_config = {
            "max_new_tokens": max_tokens,
            "pad_token_id": self.tokenizer.pad_token_id,
            "eos_token_id": self.tokenizer.eos_token_id,
            "temperature": 0,
            "do_sample": True if (self.temperature and self.temperature > 0) else False,
        }
        
        start_time = time.time()
        try:
            with torch.no_grad():
                outputs = self.model.generate(**inputs, **gen_config)
        except Exception as e:
            generation_time = time.time() - start_time
            return {
                'full_response': f'ERROR_GENERATION: {e}',
                'thinking_process': '',
                'predicted_answer': None,
                'generation_time': generation_time,
                'has_thinking': False,
                'has_json': False,
                'skip_reason': None
            }
        
        generation_time = time.time() - start_time
        # è§£ç å®Œæ•´ç”Ÿæˆï¼ˆå»æ‰è¾“å…¥éƒ¨åˆ†ï¼‰
        try:
            full_resp = self.tokenizer.decode(
                outputs[0][inputs["input_ids"].shape[1]:],
                skip_special_tokens=True
            )
        except Exception:
            full_resp = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # æ ‡å‡†åŒ–ç”¨äºé‡å¤æ£€æµ‹ï¼šcollapse whitespace, lowercase, å»æ‰ä¸å¯è§å­—ç¬¦
        norm = re.sub(r'\s+', ' ', full_resp).strip().lower()
        
        # ç®€å•ç¨³å¥çš„é‡å¤æ£€æµ‹ï¼šå¯»æ‰¾æŸä¸ªå­ä¸²åœ¨æœ«å°¾è¿ç»­é‡å¤è‹¥å¹²æ¬¡
        # æˆ‘ä»¬å°è¯•è¯†åˆ«é•¿åº¦åœ¨ 8..64 çš„ç‰‡æ®µæ˜¯å¦è¿ç»­é‡å¤ >= threshold æ¬¡
        repetition_threshold = 5
        skipped = False
        repeat_info = None
        
        # åªåœ¨é•¿æ–‡æœ¬æ—¶åšæ£€æµ‹
        if len(norm) >= 50:
            for length in range(8, min(64, len(norm)//2 + 1)):
                # è·å–æœ€è¿‘çš„ length * (threshold) é•¿åº¦ç‰‡æ®µ
                tail = norm[-(length * (repetition_threshold + 1)):] if len(norm) >= length * (repetition_threshold + 1) else norm
                # å¦‚æœå°¾éƒ¨å¤ªçŸ­ï¼Œè·³è¿‡è¯¥ length
                if len(tail) < length * 2:
                    continue
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è¿ç»­é‡å¤
                chunks = [tail[i:i+length] for i in range(0, len(tail), length)]
                # æ‰¾åˆ°æœ€åè¿ç»­é‡å¤ç‰‡æ®µæ¬¡æ•°
                # ä»å°¾éƒ¨å¾€å‰æ•°åŒä¸€ç‰‡æ®µé‡å¤æ¬¡æ•°
                last_chunk = chunks[-1]
                cnt = 1
                for ch in reversed(chunks[:-1]):
                    if ch == last_chunk:
                        cnt += 1
                    else:
                        break
                if cnt >= repetition_threshold:
                    skipped = True
                    repeat_info = {
                        'repeat_chunk': last_chunk[:100],
                        'repeat_length': length,
                        'repeat_count': cnt
                    }
                    break
        
        if skipped:
            return {
                'full_response': 'SKIPPED_DUE_TO_REPETITION',
                'thinking_process': '',
                'predicted_answer': None,
                'generation_time': generation_time,
                'has_thinking': False,
                'has_json': False,
                'skip_reason': f"detected_repetition: chunk_len={repeat_info['repeat_length']}, count={repeat_info['repeat_count']}"
            }
        
        # å¦åˆ™äº¤ç”±åŸæœ‰è§£æå™¨è§£æ
        return self._parse_response(full_resp, generation_time)

    def _parse_response(self, response: str, gen_time: float) -> Dict:
           """
        ä¿®å¤ç‰ˆæœ¬ï¼šæ›´å¼ºçš„ç­”æ¡ˆæå–é€»è¾‘
        """
        result = {
            'full_response': response,
            'thinking_process': '',
            'predicted_answer': None,
            'generation_time': gen_time,
            'has_thinking': False,
            'has_json': False
        }
        
        # æå–æ€è€ƒè¿‡ç¨‹ï¼ˆThinking æ¨¡å‹ï¼‰
        if self.is_thinking and '</think>' in response:
            result['has_thinking'] = True
            parts = response.split('</think>')
            if len(parts) >= 2:
                think_start = response.find('<think>')
                if think_start != -1:
                    result['thinking_process'] = response[think_start:response.find('</think>') + 8]
                else:
                    result['thinking_process'] = parts[0]
                response = parts[-1].strip()
        
        # ğŸ”§ æ”¹è¿›1: æ‰©å±•JSONæ¨¡å¼ï¼Œæ›´å®½æ¾çš„åŒ¹é…
        json_patterns = [
            # æ ‡å‡†æ ¼å¼
            r'\{["\']?answer["\']?\s*:\s*(\d+)\s*\}',
            r'\{["\']?answer["\']?\s*:\s*["\'](\d+)["\']\s*\}',
            
            # å®½æ¾æ ¼å¼
            r'["\']?answer["\']?\s*[:=]\s*(\d+)',
            r'\{.*?["\']?answer["\']?\s*:\s*(\d+).*?\}',
            
            # ä¸­æ–‡æ ¼å¼ï¼ˆå¦‚æœæœ‰ï¼‰
            r'\{["\']?é€‰é¡¹["\']?\s*:\s*(\d+)\s*\}',
            r'\{["\']?ç­”æ¡ˆ["\']?\s*:\s*(\d+)\s*\}',
        ]
        
        for pattern in json_patterns:
            matches = re.findall(pattern, response, re.IGNORECASE | re.DOTALL)
            if matches:
                try:
                    answer = int(matches[-1])
                    # ğŸ”§ æ”¹è¿›2: æ˜ç¡®çš„èŒƒå›´éªŒè¯ï¼ˆ1-6ï¼Œä¸æ˜¯0-5ï¼‰
                    if 1 <= answer <= 6:
                        result['predicted_answer'] = answer
                        result['has_json'] = True
                        return result
                except:
                    continue
        
        # ğŸ”§ æ”¹è¿›3: å¢å¼ºçš„æ˜ç¡®ç­”æ¡ˆå£°æ˜æ¨¡å¼
        answer_patterns = [
            # è‹±æ–‡æ¨¡å¼
            r'(?:final answer|my answer|the answer|answer)["\']?\s*(?:is|:)\s*["\']?(?:option\s*)?(\d+)["\']?',
            r'(?:option|choice)["\']?\s*["\']?(\d+)["\']?(?:\s+is correct|\s+is the answer|\s+is right)',
            r'(?:I choose|I select|select|choose)["\']?\s*(?:option|choice)?\s*["\']?(\d+)["\']?',
            r'correct answer.*?(?:is|:)\s*["\']?(?:option\s*)?(\d+)["\']?',
            r'therefore.*?answer.*?(?:is|:)\s*["\']?(\d+)["\']?',
            
            # ä¸¹éº¦è¯­æ¨¡å¼
            r'(?:det rigtige svar|mit svar|svaret)["\']?\s*(?:er|:)\s*["\']?(?:valgmulighed\s*)?(\d+)["\']?',
            r'(?:vÃ¦lger|vÃ¦lg)["\']?\s*(?:valgmulighed)?\s*["\']?(\d+)["\']?',
            
            # æ•°å­—åç›´æ¥è·Ÿç€"æ˜¯æ­£ç¡®çš„"ç­‰
            r'\b(\d+)\s*(?:is correct|is the answer|is right|er rigtig)',
        ]
        
        # ğŸ”§ æ”¹è¿›4: åˆ†æ®µæœç´¢ç­–ç•¥
        # ä¼˜å…ˆåœ¨æœ€å200å­—ç¬¦ä¸­æŸ¥æ‰¾
        search_sections = [
            response[-200:] if len(response) > 200 else response,  # æœ€å200å­—ç¬¦
            response[-500:] if len(response) > 500 else response,  # æœ€å500å­—ç¬¦
            response  # å®Œæ•´æ–‡æœ¬
        ]
        
        for search_text in search_sections:
            for pattern in answer_patterns:
                matches = re.findall(pattern, search_text, re.IGNORECASE)
                if matches:
                    try:
                        answer = int(matches[-1])
                        if 1 <= answer <= 6:
                            result['predicted_answer'] = answer
                            return result
                    except:
                        continue
        
        # ğŸ”§ æ”¹è¿›5: å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•æŸ¥æ‰¾æœ€åå‡ºç°çš„1-6æ•°å­—
        # è¿™æ˜¯æœ€åçš„å¤‡é€‰æ–¹æ¡ˆï¼Œä¼˜å…ˆçº§æœ€ä½
        last_number_pattern = r'\b([1-6])\b'
        matches = re.findall(last_number_pattern, response[-100:] if len(response) > 100 else response)
        if matches:
            try:
                answer = int(matches[-1])
                if 1 <= answer <= 6:
                    result['predicted_answer'] = answer
                    # æ³¨æ„ï¼šè¿™ç§æƒ…å†µä¸è®¾ç½® has_json=True
                    return result
            except:
                pass
        
        return result
    
    def test_single_item(self, item: Dict, language: str = "english") -> Dict:
        """æµ‹è¯•å•ä¸ªé¢˜ç›®"""
        # æ ¼å¼åŒ–é—®é¢˜
        prompt = self.format_question(item, language)
        
        # ç”Ÿæˆç­”æ¡ˆ
        result = self.generate_answer(prompt)
        
        # è·å–æ­£ç¡®ç­”æ¡ˆ
        correct_answer = int(item['answer_index'])
        predicted_answer = result['predicted_answer']
        
        # åˆ¤æ–­æ­£ç¡®æ€§
        is_correct = predicted_answer == correct_answer if predicted_answer else False
        
        return {
            'base_key': item['base_key'],
            'language': language,
            'context': item[language]['context'],
            'question': item[language]['question'],
            'correct_answer': correct_answer,
            'predicted_answer': predicted_answer,
            'is_correct': is_correct,
            'full_response': result['full_response'],
            'thinking_process': result['thinking_process'],
            'has_thinking': result['has_thinking'],
            'has_json': result['has_json'],
            'generation_time': result['generation_time'],
            'knowledge_points': ', '.join(item.get('knowledge_points', [])),
            'used_rag': self.use_rag,  # ğŸ¯ è®°å½•æ˜¯å¦ä½¿ç”¨RAG
            'rag_k': self.rag_k if self.use_rag else None,  # ğŸ¯ è®°å½•kå€¼
        }
    
    def test_dataset(self, 
                    data: List[Dict], 
                    languages: List[str] = ['english'],
                    limit: int = None,
                    checkpoint_dir: str = './checkpoints',
                    checkpoint_interval: int = 10,
                    resume: bool = False,
                    realtime_csv: bool = True,  # æ–°å¢ï¼šæ˜¯å¦å®æ—¶å†™CSV
                    output_dir: str = './results') -> pd.DataFrame:
        """
        åœ¨æ•°æ®é›†ä¸Šè¿è¡Œæµ‹è¯•ï¼ˆæ”¯æŒcheckpointã€ç»­ä¼ å’Œå®æ—¶CSVï¼‰
        """
        if limit:
            data = data[:limit]
        
        # åˆ›å»ºç›®å½•
        os.makedirs(checkpoint_dir, exist_ok=True)
        os.makedirs(output_dir, exist_ok=True)
        
        # CSVæ–‡ä»¶è·¯å¾„
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        model_short_name = self.model_name.split('/')[-1]
        rag_suffix = f"_rag_k{self.rag_k}" if self.use_rag else "_baseline"
        realtime_csv_file = None
        
        if realtime_csv:
            realtime_csv_file = f"{output_dir}/{model_short_name}_realtime_{timestamp}.csv"
            print(f"å®æ—¶CSVæ–‡ä»¶: {realtime_csv_file}")
        
        # Checkpointæ–‡ä»¶
        checkpoint_file = os.path.join(
            checkpoint_dir, 
            f"{model_short_name}_checkpoint.pkl"
        )
        
        # æ¢å¤checkpoint
        results = []
        completed_items = set()
        csv_exists = False
        
        if resume and os.path.exists(checkpoint_file):
            try:
                with open(checkpoint_file, 'rb') as f:
                    checkpoint_data = pickle.load(f)
                    results = checkpoint_data['results']
                    completed_items = checkpoint_data['completed_items']
                    print(f"âœ“ ä»checkpointæ¢å¤ï¼Œå·²å®Œæˆ: {len(completed_items)} ä¸ªæµ‹è¯•")
                    
                    # å¦‚æœæ¢å¤ï¼Œå°†å·²æœ‰ç»“æœå†™å…¥æ–°çš„CSV
                    if realtime_csv and results:
                        pd.DataFrame(results).to_csv(
                            realtime_csv_file, 
                            index=False, 
                            encoding='utf-8-sig'
                        )
                        csv_exists = True
                        
            except Exception as e:
                print(f"åŠ è½½checkpointå¤±è´¥: {e}")
        
        # æµ‹è¯•ä¸»å¾ªç¯
        total_tests = len(data) * len(languages)
        remaining_tests = total_tests - len(completed_items)
        
        print(f"\nå¼€å§‹æµ‹è¯• (å…± {total_tests} ä¸ªï¼Œå‰©ä½™ {remaining_tests} ä¸ª)")
        
        try:
            with tqdm(total=remaining_tests, desc="æµ‹è¯•è¿›åº¦") as pbar:
                for item in data:
                    for lang in languages:
                        test_id = f"{item['base_key']}_{lang}"
                        if test_id in completed_items:
                            continue
                        
                        try:
                            # æ‰§è¡Œæµ‹è¯•
                            result = self.test_single_item(item, lang)
                            results.append(result)
                            completed_items.add(test_id)
                            
                            # å®æ—¶å†™å…¥CSVï¼ˆè¿½åŠ æ¨¡å¼ï¼‰
                            if realtime_csv and realtime_csv_file:
                                result_df = pd.DataFrame([result])
                                result_df.to_csv(
                                    realtime_csv_file,
                                    mode='a',  # è¿½åŠ 
                                    header=not csv_exists,  # åªåœ¨é¦–æ¬¡å†™header
                                    index=False,
                                    encoding='utf-8-sig'
                                )
                                csv_exists = True
                            
                            # å®šæœŸä¿å­˜checkpoint
                            if len(results) % checkpoint_interval == 0:
                                self._save_checkpoint(
                                    checkpoint_file, 
                                    results, 
                                    completed_items
                                )
                                if realtime_csv:
                                    print(f"\nCheckpointä¿å­˜ + CSVå·²æ›´æ–° ({len(results)}/{total_tests})")
                                else:
                                    print(f"\nCheckpointä¿å­˜ ({len(results)}/{total_tests})")
                        
                        except KeyboardInterrupt:
                            print("\n\næ£€æµ‹åˆ°ä¸­æ–­...")
                            self._save_checkpoint(checkpoint_file, results, completed_items)
                            print(f"âœ“ è¿›åº¦å·²ä¿å­˜")
                            if realtime_csv:
                                print(f"âœ“ CSVæ–‡ä»¶: {realtime_csv_file}")
                            
                            df = pd.DataFrame(results)
                            return df
                        
                        except Exception as e:
                            print(f"\né”™è¯¯: {test_id}: {str(e)}")
                            # è®°å½•é”™è¯¯ç»“æœ
                            error_result = {
                                'base_key': item['base_key'],
                                'language': lang,
                                'is_correct': False,
                                'full_response': f"ERROR: {str(e)}",
                                # ... å…¶ä»–å­—æ®µ
                            }
                            results.append(error_result)
                            
                            # é”™è¯¯ä¹Ÿè¦å†™å…¥CSV
                            if realtime_csv and realtime_csv_file:
                                pd.DataFrame([error_result]).to_csv(
                                    realtime_csv_file,
                                    mode='a',
                                    header=not csv_exists,
                                    index=False,
                                    encoding='utf-8-sig'
                                )
                                csv_exists = True
                        
                        pbar.update(1)
            
            # æµ‹è¯•å®Œæˆ
            print(f"\nTest Doneï¼")
            if realtime_csv:
                print(f"å®æ—¶ç»“æœå·²ä¿å­˜åœ¨: {realtime_csv_file}")
            
            # åˆ é™¤checkpoint
            if len(completed_items) == total_tests and os.path.exists(checkpoint_file):
                os.remove(checkpoint_file)
                print(f"âœ“ Checkpointå·²æ¸…ç†")
        
        except Exception as e:
            print(f"\nTest error: {e}")
            self._save_checkpoint(checkpoint_file, results, completed_items)
        
        df = pd.DataFrame(results)
        return df
    
    def _save_checkpoint(self, checkpoint_file: str, results: List, completed_items: set):
        """ä¿å­˜checkpoint"""
        try:
            with open(checkpoint_file, 'wb') as f:
                pickle.dump({
                    'results': results,
                    'completed_items': completed_items,
                    'timestamp': datetime.now().isoformat()
                }, f)
        except Exception as e:
            print(f"Failed to save checkpoint: {e}")
    
    def _print_statistics(self, df: pd.DataFrame):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 80)
        print("æµ‹è¯•ç»Ÿè®¡:")
        print("=" * 80)
        
        # æ€»ä½“ç»Ÿè®¡
        print(f"\næ€»æµ‹è¯•æ•°: {len(df)}")
        print(f"æ­£ç¡®æ•°: {df['is_correct'].sum()}")
        print(f"å‡†ç¡®ç‡: {df['is_correct'].mean()*100:.2f}%")
        print(f"å¹³å‡è€—æ—¶: {df['generation_time'].mean():.2f} ç§’")
        print(f"æ€»è€—æ—¶: {df['generation_time'].sum():.1f} ç§’ ({df['generation_time'].sum()/60:.1f} åˆ†é’Ÿ)")
        
        if self.is_thinking:
            has_thinking = df['has_thinking'].sum()
            print(f"åŒ…å«æ€è€ƒè¿‡ç¨‹: {has_thinking} ({has_thinking/len(df)*100:.1f}%)")
        
        # JSON æ ¼å¼ä½¿ç”¨ç»Ÿè®¡
        has_json = df['has_json'].sum()
        print(f"ä½¿ç”¨ JSON æ ¼å¼: {has_json} ({has_json/len(df)*100:.1f}%)")
        
        # æˆåŠŸé¢„æµ‹ç»Ÿè®¡
        predicted = df['predicted_answer'].notna().sum()
        print(f"æˆåŠŸæå–ç­”æ¡ˆ: {predicted} ({predicted/len(df)*100:.1f}%)")
        
        # æŒ‰è¯­è¨€ç»Ÿè®¡
        if len(df['language'].unique()) > 1:
            print("\næŒ‰è¯­è¨€ç»Ÿè®¡:")
            lang_stats = df.groupby('language').agg({
                'is_correct': ['count', 'sum', 'mean'],
                'generation_time': 'mean',
                'has_json': 'sum'
            }).round(3)
            lang_stats.columns = ['é¢˜ç›®æ•°', 'æ­£ç¡®æ•°', 'å‡†ç¡®ç‡', 'å¹³å‡è€—æ—¶(ç§’)', 'JSONæ ¼å¼æ•°']
            lang_stats['å‡†ç¡®ç‡'] = (lang_stats['å‡†ç¡®ç‡'] * 100).round(2)
            print(lang_stats)
    
    def _analyze_errors(self, df: pd.DataFrame):
        """åˆ†æé”™è¯¯æ ·æœ¬"""
        errors = df[df['is_correct'] == False].copy()
        
        
        print(f"\n{'='*80}")
        print(f"é”™è¯¯åˆ†æ (å…± {len(errors)} ä¸ªé”™è¯¯ï¼Œé”™è¯¯ç‡ {len(errors)/len(df)*100:.2f}%)")
        print(f"{'='*80}")
        
        # é”™è¯¯åŸå› åˆ†ç±»
        no_answer = errors['predicted_answer'].isna().sum()
        wrong_answer = len(errors) - no_answer
        
        print(f"\né”™è¯¯ç±»å‹:")
        print(f"  âŒ æœªèƒ½æå–ç­”æ¡ˆ: {no_answer} ({no_answer/len(errors)*100:.1f}%)")
        print(f"  âŒ ç­”æ¡ˆé”™è¯¯: {wrong_answer} ({wrong_answer/len(errors)*100:.1f}%)")


def load_jsonl_data(file_path: str) -> List[Dict]:
    """åŠ è½½ JSONL æ ¼å¼çš„æ•°æ®"""
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                data.append(json.loads(line))
    
    print(f"âœ“ æˆåŠŸåŠ è½½ {len(data)} é“é¢˜ç›®")
    return data


def compare_models(data: List[Dict],
                   model_configs: List[Dict],
                   languages: List[str] = ['english'],
                   output_dir: str = './results',
                   limit: int = None,
                   checkpoint_dir: str = './checkpoints',
                   resume: bool = False):
    """
    å¯¹æ¯”å¤šä¸ªæ¨¡å‹ï¼ˆæ”¯æŒcheckpointï¼‰
    
    Args:
        data: æµ‹è¯•æ•°æ®
        model_configs: æ¨¡å‹é…ç½®åˆ—è¡¨
        languages: æµ‹è¯•è¯­è¨€åˆ—è¡¨
        output_dir: ç»“æœä¿å­˜ç›®å½•
        limit: é™åˆ¶æµ‹è¯•æ•°é‡
        checkpoint_dir: checkpointä¿å­˜ç›®å½•
        resume: æ˜¯å¦ä»checkpointæ¢å¤
    """
    os.makedirs(output_dir, exist_ok=True)
    
    all_results = {}
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    for config in model_configs:
        model_name = config['name']
        use_quant = config.get('use_quantization', False)
        quant_bits = config.get('quantization_bits', 4)
        local_path = config.get('local_path', None)
        temperature = config.get('temperature', 0.0)
        use_rag = config.get('use_rag', False)
        rag_system = config.get('rag_system', None)
        rag_k = config.get('rag_k', 3)
        
        print(f"\n{'='*80}")
        print(f"æµ‹è¯•æ¨¡å‹: {model_name}")
        if use_quant:
            print(f"é‡åŒ–é…ç½®: {quant_bits}-bit")
        if local_path:
            print(f"æœ¬åœ°è·¯å¾„: {local_path}")
        print(f"æ¸©åº¦: {temperature}")
        print(f"{'='*80}\n")
        
        try:
            # åˆ›å»ºæµ‹è¯•å™¨
            tester = ProbabilityTestFramework(
                model_name,
                use_quantization=use_quant,
                quantization_bits=quant_bits,
                local_model_path=local_path,
                temperature=temperature,
                use_rag=use_rag,
                rag_system=rag_system,
                rag_k=rag_k
            )
            
            # è¿è¡Œæµ‹è¯•ï¼ˆæ”¯æŒcheckpointï¼‰
            results_df = tester.test_dataset(
                data, 
                languages, 
                limit,
                checkpoint_dir=checkpoint_dir,
                checkpoint_interval=10,  # æ¯10é¢˜ä¿å­˜ä¸€æ¬¡
                resume=resume
            )
            
            # ä¿å­˜è¯¦ç»†ç»“æœ
            model_short_name = model_name.split('/')[-1]
            quant_suffix = f"_q{quant_bits}" if use_quant else ""
            rag_suffix = f"_rag_k{rag_k}" if use_rag else "_baseline"
            temp_suffix = f"_t{temperature}".replace('.', '')
            output_file = f"{output_dir}/{model_short_name}{quant_suffix}{temp_suffix}_{timestamp}.csv"
            results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            print(f"\nâœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            
            all_results[f"{model_name}{quant_suffix}"] = results_df
            
            # æ¸…ç†æ˜¾å­˜
            del tester
            torch.cuda.empty_cache()
            
        except Exception as e:
            print(f"\nâœ— æ¨¡å‹ {model_name} æµ‹è¯•å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    if len(all_results) > 1:
        generate_comparison_report(all_results, output_dir, timestamp)
    
    return all_results


def generate_comparison_report(all_results: Dict[str, pd.DataFrame],
                               output_dir: str,
                               timestamp: str):
    """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
    print("\n" + "="*80)
    print("æ¨¡å‹å¯¹æ¯”æŠ¥å‘Š")
    print("="*80)
    
    comparison_data = []
    
    for model_name, df in all_results.items():
        comparison_data.append({
            'æ¨¡å‹': model_name.split('/')[-1],
            'é¢˜ç›®æ•°': len(df),
            'å‡†ç¡®ç‡(%)': f"{df['is_correct'].mean()*100:.2f}",
            'å¹³å‡è€—æ—¶(ç§’)': f"{df['generation_time'].mean():.2f}",
            'æ€»è€—æ—¶(åˆ†é’Ÿ)': f"{df['generation_time'].sum()/60:.1f}",
            'æˆåŠŸé¢„æµ‹æ•°': df['predicted_answer'].notna().sum(),
            'JSONæ ¼å¼æ•°': df['has_json'].sum(),
        })
    
    comparison_df = pd.DataFrame(comparison_data)
    print("\n", comparison_df.to_string(index=False))
    
    # ä¿å­˜å¯¹æ¯”æŠ¥å‘Š
    report_file = f"{output_dir}/comparison_report_{timestamp}.csv"
    comparison_df.to_csv(report_file, index=False, encoding='utf-8-sig')
    print(f"\nâœ“ å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")


# ============================================================================
# ä¸»ç¨‹åº
# ============================================================================

if __name__ == "__main__":
    print("="*80)
    print("æ¦‚ç‡è®ºé¢˜åº“æµ‹è¯•æ¡†æ¶ v3.0")
    print("âœ… æ”¯æŒcheckpointå’Œç»­ä¼ ")
    print("âœ… æ”¯æŒæœ¬åœ°æ¨¡å‹åŠ è½½")
    print("âœ… æ”¯æŒæ¸©åº¦0ï¼ˆç¡®å®šæ€§è¾“å‡ºï¼‰")
    print("="*80)
    
    # 1. åŠ è½½æµ‹è¯•æ•°æ®
    data = load_jsonl_data('probability_test_set.jsonl')
    
    # 2. å®šä¹‰æµ‹è¯•é…ç½®
    QUICK_TEST = False  # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
    test_limit = 10 if QUICK_TEST else None
    
    # è¦æµ‹è¯•çš„è¯­è¨€
    test_languages = ['english', 'danish']
    
    # è¦æµ‹è¯•çš„æ¨¡å‹é…ç½®
    model_configs = [
        # æœ¬åœ°é‡åŒ–æ¨¡å‹ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
        {
            'name': 'Qwen/Qwen3-14B',
            'local_path': '/root/models/qwen3-14b-q4',  # æœ¬åœ°è·¯å¾„
            'use_quantization': True,
            'quantization_bits': 4,
            'timeout': 120,  # æ¯é¢˜æœ€å¤š120ç§’
            'temperature': 0.0  # ç¡®å®šæ€§è¾“å‡º
        },
        
        # å¦‚æœéœ€è¦æµ‹è¯•å…¶ä»–æ¨¡å‹ï¼Œæ·»åŠ åœ¨è¿™é‡Œ
        # {
        #     'name': 'Qwen/Qwen3-4B-Thinking-2507',
        #     'local_path': '/root/models/qwen3-4b-thinking',
        #     'use_quantization': False,
        #     'temperature': 0.0
        # },
    ]
    
    # 3. è¿è¡Œå¯¹æ¯”æµ‹è¯•
    print(f"\né…ç½®:")
    print(f"  æµ‹è¯•æ¨¡å¼: {'å¿«é€Ÿæµ‹è¯• (å‰' + str(test_limit) + 'é¢˜)' if QUICK_TEST else 'å®Œæ•´æµ‹è¯•'}")
    print(f"  æµ‹è¯•è¯­è¨€: {', '.join(test_languages)}")
    print(f"  æ¨¡å‹æ•°é‡: {len(model_configs)}")
    print(f"  Checkpoint: å¯ç”¨ï¼ˆæ¯10é¢˜ä¿å­˜ï¼‰")
    print(f"  æ”¯æŒä¸­æ–­: Ctrl+C å®‰å…¨ä¸­æ–­å¹¶ä¿å­˜è¿›åº¦")
    
    results = compare_models(
        data=data,
        model_configs=model_configs,
        languages=test_languages,
        output_dir='./probability_test_results',
        checkpoint_dir='./checkpoints',
        limit=test_limit,
        resume=False  # å¯ç”¨ç»­ä¼ 
    )
    
    print("\n" + "="*80)
    print("æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("="*80)