## Comparison of LLMs on a Probability Theory Question


We deployed three large language models locally:
- **Deepseek-14B**
- **Qwen-14B**
- **Phi-4**

We gave them the same question, using just the bare problem statement (without any additional prompts or context). My aim was to test the models' out-of-the-box mathematical reasoning and problem-solving abilities.

## Results

- **Qwen-14B** was the only model that provided the correct answer.
- Both **Deepseek-14B** and **Phi-4** failed to solve the problem correctly.
